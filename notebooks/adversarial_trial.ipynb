{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spikingjelly\n",
    "from spikingjelly.activation_based.model import spiking_resnet\n",
    "from spikingjelly.activation_based import surrogate, neuron, functional, layer\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np\n",
    "from spikingjelly.activation_based.model.sew_resnet import sew_resnet18\n",
    "from torch import nn\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW INPUT SHAPE: torch.Size([1, 1, 28, 28])\n",
      "tensor([[[[-3.4519e-01,  9.1727e-02, -4.6358e-01, -1.2695e+00,  1.2693e+00,\n",
      "            2.4674e-02, -5.7668e-01, -1.6995e+00, -1.1081e+00, -9.3229e-01,\n",
      "            1.4014e+00,  2.2841e-01, -7.8185e-01, -8.9732e-01,  3.4407e-01,\n",
      "            1.0203e+00,  5.0452e-01, -1.1258e+00,  3.7464e-01,  3.4553e-01,\n",
      "           -2.7075e-03, -4.5000e-01, -1.1760e+00,  1.7577e-02, -1.0302e+00,\n",
      "            3.5220e-02, -3.3523e-01,  7.1252e-01],\n",
      "          [ 1.2366e+00, -1.5124e+00,  1.0330e+00,  1.9119e+00, -1.1545e+00,\n",
      "           -1.5810e-01,  1.2688e+00, -1.8234e+00, -6.9158e-01,  1.2743e+00,\n",
      "            1.2276e+00, -1.0755e+00,  2.0838e-01,  1.8423e-01, -2.8349e-01,\n",
      "            1.8100e+00, -1.6409e+00,  2.2434e+00, -3.6947e-01,  6.6441e-01,\n",
      "           -4.6507e-01, -7.3347e-01, -1.3598e+00,  7.5758e-02,  1.4354e+00,\n",
      "           -5.5126e-01,  1.2559e+00, -8.4321e-01],\n",
      "          [ 3.2449e-01,  7.4277e-01,  5.5155e-01,  3.5231e-01, -2.7423e-01,\n",
      "           -7.9102e-01, -1.6252e+00, -1.9777e-02,  5.5244e-01,  7.8804e-01,\n",
      "            6.4649e-01, -6.1378e-02, -4.1201e-01,  1.5583e+00, -2.1694e-01,\n",
      "           -7.1192e-01,  2.1216e+00,  3.9601e-01,  1.1694e+00,  1.4054e+00,\n",
      "            1.4100e+00, -1.8246e+00,  7.5717e-01, -1.0724e+00,  1.0835e+00,\n",
      "           -2.6946e-01,  1.8779e-01, -7.5597e-02],\n",
      "          [ 6.2471e-01, -4.6169e-01, -8.9444e-01, -1.8718e+00, -1.7792e-01,\n",
      "           -5.0760e-01, -1.8302e-01,  1.4819e-01,  8.1834e-01, -6.8737e-02,\n",
      "           -2.1572e+00, -1.2910e-01, -1.7918e+00,  1.3333e-01,  4.5424e-01,\n",
      "           -2.4116e+00, -5.0901e-01,  1.2278e-02, -2.4447e-01,  7.5019e-01,\n",
      "           -4.6490e-03, -1.2279e+00, -5.3430e-01,  8.8113e-01, -2.0563e+00,\n",
      "           -1.4491e+00, -5.2212e-01,  2.6262e-01],\n",
      "          [-1.1425e+00, -1.5709e+00,  9.7294e-01,  5.9162e-01, -1.5360e+00,\n",
      "            4.0434e-02, -4.9432e-01,  2.5787e-01,  1.6621e+00,  8.2385e-01,\n",
      "            2.2189e-01,  6.7958e-01,  1.0739e+00, -4.0290e-01, -6.9148e-01,\n",
      "           -7.2704e-01,  1.0621e+00, -1.7033e+00,  4.0415e-01,  6.4733e-01,\n",
      "            8.4091e-01,  6.2031e-01,  5.7808e-01,  7.5089e-01,  3.2278e-01,\n",
      "            7.8797e-01, -1.4667e+00, -2.7225e-01],\n",
      "          [ 2.9227e-01,  1.6665e+00, -4.9218e-01, -5.6441e-01, -2.8737e-01,\n",
      "            3.8368e-01, -2.1089e+00, -9.0180e-01,  8.7331e-01, -6.1601e-01,\n",
      "           -2.0815e+00,  2.1440e-01, -1.5901e-01,  3.6453e-01,  2.5130e-01,\n",
      "           -1.0649e-01, -5.7970e-01,  1.3307e+00, -1.1001e+00,  8.3241e-01,\n",
      "            1.2978e+00,  4.3491e-01,  4.6072e-01, -1.2126e+00, -4.6371e-01,\n",
      "           -4.8331e-01, -1.2038e+00, -6.1570e-01],\n",
      "          [ 6.6928e-01,  4.9314e-01,  1.4449e-01, -5.8158e-01,  8.7785e-01,\n",
      "            2.0874e+00,  2.7244e-01,  4.2805e-01, -1.7724e-01, -5.3173e-01,\n",
      "            6.0124e-01,  3.5695e-01,  3.9610e-01, -1.0617e+00, -4.1882e-01,\n",
      "           -1.9073e-01,  9.3669e-01, -2.8228e-01, -7.8804e-02,  6.9343e-01,\n",
      "            5.1905e-01,  2.5232e-01,  2.8775e-01, -2.1767e+00, -2.9488e-01,\n",
      "            8.0405e-01, -3.0233e-01,  3.9262e-01],\n",
      "          [-1.0565e+00,  1.0287e+00, -8.1915e-01, -1.1891e-01,  9.9836e-01,\n",
      "            8.6781e-01,  9.0970e-01,  1.8069e-01,  9.4588e-01,  5.2702e-01,\n",
      "            1.1403e-01, -8.6063e-01,  1.6828e+00, -2.0267e+00,  5.5841e-01,\n",
      "            1.5120e+00, -1.6602e+00, -2.9800e-01,  1.2104e+00,  6.0094e-01,\n",
      "            4.0531e-01,  8.8732e-02, -1.3778e-01,  1.5753e+00, -6.2884e-01,\n",
      "           -2.9792e+00,  3.1878e-01, -8.5562e-01],\n",
      "          [-2.9263e+00,  5.5033e-01,  8.1964e-02,  1.0682e+00,  2.8386e-01,\n",
      "            6.0229e-01, -1.6113e+00, -1.4570e-01, -1.0650e+00, -5.0317e-01,\n",
      "           -1.4879e+00,  7.5628e-01,  1.3064e+00, -9.9766e-01, -1.7646e-01,\n",
      "            9.8754e-01, -4.2569e-01,  3.6146e-01, -8.7338e-01,  1.4601e+00,\n",
      "           -2.3520e-01, -1.7759e-01,  9.0551e-01,  4.0935e-01,  1.6750e-01,\n",
      "           -3.9291e-01, -6.9560e-02,  1.4193e+00],\n",
      "          [ 5.9584e-01, -7.2069e-01,  1.7774e+00, -1.3411e+00,  1.0945e+00,\n",
      "            4.6217e-01, -1.0942e-01, -1.4050e-01,  7.9564e-01, -8.4470e-02,\n",
      "           -3.1169e+00, -1.0754e+00, -7.5811e-01,  7.0187e-01,  1.2096e+00,\n",
      "            4.0473e-01,  3.0527e-01,  7.8298e-01,  5.0990e-01, -4.7341e-01,\n",
      "            2.0404e+00,  5.4794e-01,  1.6895e+00,  5.0330e-01,  8.9606e-01,\n",
      "            1.2194e+00, -1.1812e+00, -1.5577e+00],\n",
      "          [-2.6288e-01, -1.8464e-01,  1.3169e+00,  4.0200e-01, -1.3873e+00,\n",
      "           -6.7573e-01,  3.0925e-01, -1.0297e+00,  1.1944e+00, -1.0267e+00,\n",
      "           -1.7356e+00,  1.0933e+00, -2.1118e+00, -1.7000e+00, -3.1050e-01,\n",
      "           -3.5171e-01,  2.7382e-01, -2.7833e+00,  6.5873e-01, -3.7223e-01,\n",
      "           -1.7364e+00,  4.2760e-02, -1.4972e-01,  1.8475e-01, -1.8210e+00,\n",
      "           -1.4497e-01,  2.9461e-01, -8.3518e-01],\n",
      "          [ 9.7364e-01,  1.1728e+00, -3.7362e-01, -2.1506e-01,  3.9974e-01,\n",
      "           -6.2423e-01, -9.9693e-02, -6.3349e-01,  6.5693e-01,  8.5375e-01,\n",
      "            1.1132e+00, -3.4920e-01,  6.2857e-01,  2.5291e+00, -4.2117e-01,\n",
      "           -1.7774e+00, -7.4080e-01,  1.0474e-01, -2.8142e-01,  1.5261e-02,\n",
      "            4.3542e-01, -1.7717e+00,  8.8420e-01,  1.1958e+00, -5.5067e-01,\n",
      "            8.2003e-01, -6.9988e-01, -4.9978e-01],\n",
      "          [ 2.2427e-01,  1.1018e+00,  5.2713e-01,  4.6202e-01, -1.1391e+00,\n",
      "            2.9380e-02,  1.0513e+00, -2.7743e-01,  8.0352e-01,  1.0152e+00,\n",
      "           -4.0239e-01, -1.5762e-01,  4.4927e-01, -5.4582e-01,  7.2211e-01,\n",
      "           -8.5603e-01, -2.1634e-01,  2.6678e+00,  9.8671e-02,  1.7832e+00,\n",
      "            6.2274e-01, -1.1922e+00,  1.1481e+00, -2.8979e-01, -5.8735e-01,\n",
      "           -3.5478e-01, -9.8502e-01,  1.7094e+00],\n",
      "          [ 1.8227e-01,  6.3416e-01, -2.2874e-01,  1.6916e+00, -1.9782e-02,\n",
      "            1.3285e+00,  8.5719e-01, -5.7026e-01, -8.6866e-01, -4.3316e-01,\n",
      "            1.9423e-01,  7.4780e-01,  5.7002e-01,  9.9657e-01,  5.2476e-01,\n",
      "            7.3637e-01, -5.1547e-01, -9.9743e-01, -8.7669e-01, -2.4326e-01,\n",
      "           -1.3298e+00, -2.1398e-01,  6.4982e-01, -1.3003e+00, -1.8423e-01,\n",
      "           -4.1592e-01,  1.1470e-01, -1.4790e-01],\n",
      "          [ 1.3556e+00, -1.7190e+00, -5.7730e-02, -2.5653e+00,  6.5302e-01,\n",
      "            1.6840e+00, -2.2256e+00, -5.3146e-02,  9.9210e-01,  3.9032e-01,\n",
      "            6.2440e-01, -1.6429e-01,  4.1794e-01, -1.3060e+00,  5.0120e-01,\n",
      "           -2.5709e-01,  3.5250e-01,  8.7821e-01, -1.3019e+00,  2.5243e-01,\n",
      "            1.7956e-01, -1.4721e+00, -2.3376e-01, -6.1145e-01, -4.3030e-01,\n",
      "            1.0076e+00,  3.9590e-01,  8.4977e-02],\n",
      "          [ 9.8497e-01, -1.9181e-01,  2.9423e-01,  3.6078e-01, -8.4644e-01,\n",
      "           -1.6464e+00,  7.6517e-01,  2.2367e+00,  2.4593e-01,  1.1808e+00,\n",
      "           -1.0034e+00, -1.8425e+00,  2.4241e+00,  1.4541e+00, -1.2043e+00,\n",
      "            2.2978e+00, -9.0057e-02, -1.8831e+00, -4.3220e-01,  6.0739e-01,\n",
      "            4.5152e-01, -4.5711e-01, -7.9911e-02, -7.8708e-01,  1.0169e+00,\n",
      "            3.3085e-01, -2.5066e-01,  6.7055e-01],\n",
      "          [ 1.4245e-01, -1.7092e-01,  2.5906e-01,  3.6781e-01, -6.8031e-01,\n",
      "            1.3134e-01, -5.1215e-01, -5.0927e-01, -1.1729e+00,  1.0494e+00,\n",
      "           -4.0082e-01, -1.1282e+00, -1.1519e+00,  1.1312e+00, -8.2706e-01,\n",
      "           -1.9455e-02, -3.4678e-01, -2.4582e-01,  1.6385e-01,  1.6829e+00,\n",
      "            7.1437e-01,  3.6723e-01,  1.0772e+00,  1.8185e-01,  8.6080e-01,\n",
      "            1.2169e+00,  1.1707e+00, -1.0720e+00],\n",
      "          [-2.8769e+00,  6.2074e-01,  4.7531e-01, -1.0883e+00,  1.3843e-02,\n",
      "            1.0285e+00, -1.9887e+00,  1.3318e+00, -5.2406e-01, -1.2875e+00,\n",
      "           -1.8064e+00,  2.2658e-01,  1.0565e+00, -2.9331e-01, -3.1525e-01,\n",
      "            4.8846e-01, -3.7512e-01,  9.3773e-01,  3.8054e-01,  1.4686e+00,\n",
      "            1.7867e+00,  1.4599e+00,  8.6344e-01, -1.9480e-01, -1.2471e+00,\n",
      "           -4.5235e-01, -5.5442e-01,  6.5733e-01],\n",
      "          [ 4.4317e-01,  1.9607e-01,  4.5435e-01,  1.0504e+00, -9.5306e-01,\n",
      "            3.8748e-01,  2.0296e-01,  1.0607e+00, -1.6664e-01,  1.5077e+00,\n",
      "           -8.7583e-01,  1.4300e+00,  1.2667e+00, -1.9830e+00,  5.9861e-01,\n",
      "           -6.2661e-01,  1.2230e-01,  1.4505e+00,  1.6437e+00, -9.1881e-01,\n",
      "            1.5038e+00, -4.9738e-01,  1.0767e+00, -4.1144e-01, -7.1846e-01,\n",
      "           -1.9720e+00,  6.1531e-01, -7.0546e-01],\n",
      "          [ 3.8113e-01,  3.5680e-01,  2.0186e-01, -2.9125e-01,  3.1730e-01,\n",
      "            3.0515e-01,  9.9320e-01, -2.0903e+00,  1.7833e+00,  2.5444e+00,\n",
      "           -1.2147e+00,  8.2680e-01, -2.9667e-01, -3.1981e-01, -2.8444e-02,\n",
      "            1.4476e-01, -1.5826e+00,  2.8320e-01, -3.3214e-01,  8.3653e-01,\n",
      "            2.0082e-01,  2.9974e-01,  2.5019e-02,  1.0981e-01,  9.3460e-01,\n",
      "            2.4786e-03,  1.1162e+00, -3.0066e+00],\n",
      "          [-9.8803e-01,  3.8790e-01, -4.0978e-01, -8.5222e-01,  1.0117e-01,\n",
      "           -2.0029e-01,  4.0812e-02,  1.1838e+00, -5.9035e-01, -7.3370e-01,\n",
      "           -1.1738e+00,  6.3031e-01, -1.5722e+00,  7.7815e-01, -1.9478e-01,\n",
      "            2.4651e+00, -6.2080e-01, -3.2318e-01,  1.8569e+00,  1.1251e+00,\n",
      "            4.2556e-01,  1.3021e+00,  4.8131e-02,  5.9245e-01,  1.7056e+00,\n",
      "            9.4410e-01, -1.8512e-01,  9.0304e-01],\n",
      "          [ 1.0964e+00, -1.5744e+00,  1.0905e-01, -1.5534e+00, -1.4517e-01,\n",
      "           -1.0081e+00,  1.5618e-01, -1.3689e+00,  1.0354e+00, -1.8620e+00,\n",
      "           -2.6013e-01, -1.5328e+00, -2.4047e-01, -3.0815e-01,  1.2709e+00,\n",
      "           -7.5836e-01, -3.1273e-01, -5.7941e-02,  1.4355e-01,  1.2889e+00,\n",
      "            5.9632e-02,  7.4896e-01,  8.9023e-01,  1.9725e-01,  7.5031e-01,\n",
      "            5.0964e-01,  8.2955e-01,  9.8709e-02],\n",
      "          [-3.5412e-01, -7.0662e-01,  4.0432e-01,  3.8992e-01,  2.3769e+00,\n",
      "            1.5679e+00,  1.4269e-01, -1.2469e-01, -7.8753e-01, -7.2936e-01,\n",
      "            3.6719e-01,  2.7651e-01, -1.3700e+00, -3.8485e-01, -5.6408e-01,\n",
      "           -2.9773e-01, -1.7990e+00,  3.4246e-01,  1.2275e+00,  2.0162e+00,\n",
      "            1.4136e+00, -4.9698e-01,  4.1334e-01,  6.2604e-01,  5.8020e-02,\n",
      "           -3.8195e-01,  1.7080e-01,  1.7689e-01],\n",
      "          [-9.1612e-01, -1.4006e+00, -4.2189e-01, -5.8493e-01,  4.4149e-01,\n",
      "            7.7315e-01, -1.3296e-01, -1.1806e-01,  4.8823e-01, -8.8461e-01,\n",
      "            1.6469e+00, -9.3488e-01,  1.4700e+00,  1.0549e+00,  6.2491e-01,\n",
      "            5.9038e-02, -1.8133e+00,  3.1945e-01, -1.2077e+00, -2.1486e-01,\n",
      "           -1.1396e+00,  1.4914e+00,  1.5073e+00, -1.0089e+00, -8.2276e-01,\n",
      "           -9.8328e-01,  1.5603e-01,  2.9675e-01],\n",
      "          [ 2.4454e-01, -4.2358e-01, -1.2601e+00, -8.6193e-02, -7.0903e-01,\n",
      "           -7.0693e-03, -1.0034e+00, -7.4586e-01, -3.1826e-01, -5.2267e-01,\n",
      "           -5.1965e-01, -1.5089e+00, -1.1085e+00, -3.8186e-01, -1.7419e+00,\n",
      "            9.4259e-01,  2.7318e-01,  6.0318e-01,  1.5523e+00,  3.0216e-01,\n",
      "            2.3991e-01, -4.6516e-01,  2.0534e+00,  4.9825e-01, -2.0437e+00,\n",
      "            1.5531e+00,  2.3953e-01, -2.0512e-01],\n",
      "          [ 5.8947e-01,  3.4685e-01,  1.6120e+00,  5.2201e-01,  1.0487e+00,\n",
      "           -6.2258e-01, -1.3739e-01, -2.6728e+00,  1.3053e-01,  2.5221e-02,\n",
      "           -4.6397e-01, -3.7760e-01,  1.5096e+00, -5.1515e-02, -6.8642e-01,\n",
      "            3.2561e-01,  1.2953e+00, -3.2219e-01, -9.3639e-01,  2.3121e-01,\n",
      "            1.1268e+00, -3.6912e-01,  1.7731e-01, -3.3308e-01,  7.7487e-01,\n",
      "           -2.4024e-02,  7.9037e-01, -3.4413e-01],\n",
      "          [ 4.6566e-01,  5.6697e-01, -7.0634e-02,  1.3913e+00, -9.0407e-01,\n",
      "           -3.5570e-01, -2.4245e-01, -8.4085e-01, -9.7817e-01, -6.0405e-01,\n",
      "            1.3693e+00,  1.6940e+00,  3.5798e-03,  1.0328e-01, -1.6642e-03,\n",
      "           -9.1045e-01, -1.1705e+00, -1.5899e+00,  9.1401e-01, -4.9826e-01,\n",
      "           -2.1710e+00,  5.1707e-01, -9.4177e-01,  1.9145e-01,  1.0101e+00,\n",
      "            2.8042e-01, -5.8819e-01,  1.4622e-01],\n",
      "          [-2.8331e-01,  9.8306e-01,  2.7025e-01, -7.8213e-01,  5.4747e-01,\n",
      "            7.8176e-01, -9.2875e-01,  4.7572e-02, -9.1184e-01, -7.9862e-01,\n",
      "           -1.4669e+00,  1.3126e-01,  8.0506e-01,  2.5915e+00, -4.6327e-01,\n",
      "            1.6505e+00, -1.8073e-01, -8.9094e-01,  1.6221e+00, -1.4369e+00,\n",
      "           -3.2265e-01,  1.7433e+00,  3.5429e-01,  1.1704e-01,  4.4378e-01,\n",
      "           -8.9008e-03,  1.5203e+00,  3.8172e-01]]]])\n",
      "AFTER CONV SHAPE: torch.Size([1, 16, 28, 28])\n",
      "tensor([[[[ 0.0369,  0.3732, -1.5227,  ...,  0.0822, -0.1937,  0.6606],\n",
      "          [-0.4681, -0.0424,  0.6146,  ...,  0.7686, -0.3822,  0.2009],\n",
      "          [ 0.8168,  0.0323,  0.6299,  ..., -0.6310,  0.1986, -0.5336],\n",
      "          ...,\n",
      "          [ 0.0375,  0.6188, -0.0270,  ...,  1.0217,  0.1876, -0.2826],\n",
      "          [-0.0073, -0.7697,  0.8277,  ..., -0.5984, -0.3019,  0.1513],\n",
      "          [ 0.0537,  0.2577, -0.5112,  ...,  0.4047,  0.1018,  0.2470]],\n",
      "\n",
      "         [[-0.0452,  0.7836,  0.4457,  ...,  0.8738,  0.0192,  0.5838],\n",
      "          [ 0.4813,  0.5017,  0.7872,  ...,  0.6191,  0.1785,  0.3625],\n",
      "          [ 0.5824, -0.1066, -0.2732,  ..., -0.4996,  0.4349,  0.0718],\n",
      "          ...,\n",
      "          [ 0.5643,  0.5461,  0.7346,  ...,  0.5677,  0.3979,  0.1516],\n",
      "          [ 0.5698,  0.0764,  0.3414,  ...,  0.5403,  0.4800,  0.5157],\n",
      "          [ 0.2704,  0.4106,  0.0374,  ...,  0.3820,  0.3081,  0.3490]],\n",
      "\n",
      "         [[-0.2987,  0.5566,  0.6541,  ...,  0.1545, -0.1331,  0.2675],\n",
      "          [ 0.5095,  0.4442, -0.0127,  ...,  0.7627,  0.0980,  0.6215],\n",
      "          [ 0.5307, -0.4074,  0.4020,  ...,  0.3716,  1.0729, -0.0173],\n",
      "          ...,\n",
      "          [ 0.4374,  0.3932,  0.7052,  ...,  0.6336,  0.1922,  0.4303],\n",
      "          [ 0.4720, -0.2181, -0.1337,  ...,  0.3881,  0.1430, -0.3950],\n",
      "          [ 0.0703,  0.2428,  0.0965,  ...,  0.2263,  0.2718,  0.8545]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1960, -0.2773, -0.6837,  ..., -0.0801, -0.1164,  0.0608],\n",
      "          [-0.2428, -0.8915,  0.4642,  ..., -0.4200,  0.2403, -0.5729],\n",
      "          [ 0.1073, -0.5361,  1.0369,  ..., -0.8047,  0.3097, -0.8743],\n",
      "          ...,\n",
      "          [-0.0244, -0.4531, -0.1106,  ...,  0.7547, -0.4684, -0.6691],\n",
      "          [ 0.1979,  0.0317,  0.3100,  ..., -0.7540, -0.3176, -0.3696],\n",
      "          [ 0.1225,  0.2364, -0.4952,  ..., -0.4072,  0.1011, -0.3659]],\n",
      "\n",
      "         [[ 0.1052, -0.3615,  0.0605,  ..., -0.6283,  0.0614, -0.2870],\n",
      "          [ 0.0198,  0.0931, -1.0559,  ...,  0.2134,  0.0439,  0.3677],\n",
      "          [-0.3456,  0.0509,  1.0400,  ...,  0.6217, -0.0444, -0.1158],\n",
      "          ...,\n",
      "          [-0.2116, -0.3449, -0.1645,  ...,  0.4323, -0.3227,  0.2265],\n",
      "          [-0.1063,  0.3661,  0.0668,  ...,  0.1501, -0.0714, -0.5190],\n",
      "          [ 0.0030, -0.2143,  0.5249,  ..., -0.2905, -0.0857,  0.5028]],\n",
      "\n",
      "         [[ 0.3008, -0.2205, -0.5408,  ..., -0.0681,  0.0248,  0.2204],\n",
      "          [ 0.3317, -0.2703,  0.4940,  ...,  0.1895,  0.1771, -0.2019],\n",
      "          [ 0.4446, -0.2782,  0.0956,  ..., -1.4731, -0.1552, -0.5107],\n",
      "          ...,\n",
      "          [ 0.1371,  0.3169,  0.3859,  ...,  0.7261, -0.3245, -0.3319],\n",
      "          [-0.3103, -0.3665, -0.0903,  ..., -0.5048,  0.0280,  0.1201],\n",
      "          [-0.3879,  0.0343, -0.3983,  ..., -0.3902,  0.2178,  0.2154]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "AFTER BN SHAPE: torch.Size([1, 16, 28, 28])\n",
      "tensor([[[[ 0.0369,  0.3732, -1.5226,  ...,  0.0822, -0.1937,  0.6606],\n",
      "          [-0.4681, -0.0424,  0.6146,  ...,  0.7686, -0.3822,  0.2009],\n",
      "          [ 0.8168,  0.0323,  0.6299,  ..., -0.6310,  0.1986, -0.5336],\n",
      "          ...,\n",
      "          [ 0.0375,  0.6188, -0.0270,  ...,  1.0217,  0.1876, -0.2826],\n",
      "          [-0.0073, -0.7697,  0.8277,  ..., -0.5984, -0.3019,  0.1513],\n",
      "          [ 0.0537,  0.2577, -0.5112,  ...,  0.4047,  0.1018,  0.2470]],\n",
      "\n",
      "         [[-0.0452,  0.7836,  0.4457,  ...,  0.8738,  0.0192,  0.5838],\n",
      "          [ 0.4813,  0.5017,  0.7872,  ...,  0.6191,  0.1785,  0.3625],\n",
      "          [ 0.5824, -0.1066, -0.2732,  ..., -0.4996,  0.4349,  0.0718],\n",
      "          ...,\n",
      "          [ 0.5643,  0.5461,  0.7346,  ...,  0.5677,  0.3979,  0.1516],\n",
      "          [ 0.5698,  0.0764,  0.3414,  ...,  0.5403,  0.4800,  0.5157],\n",
      "          [ 0.2704,  0.4106,  0.0374,  ...,  0.3820,  0.3081,  0.3490]],\n",
      "\n",
      "         [[-0.2987,  0.5566,  0.6541,  ...,  0.1545, -0.1331,  0.2675],\n",
      "          [ 0.5095,  0.4442, -0.0127,  ...,  0.7627,  0.0980,  0.6215],\n",
      "          [ 0.5307, -0.4074,  0.4020,  ...,  0.3716,  1.0729, -0.0173],\n",
      "          ...,\n",
      "          [ 0.4374,  0.3932,  0.7052,  ...,  0.6336,  0.1922,  0.4303],\n",
      "          [ 0.4720, -0.2181, -0.1337,  ...,  0.3881,  0.1430, -0.3950],\n",
      "          [ 0.0703,  0.2428,  0.0965,  ...,  0.2263,  0.2718,  0.8545]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1960, -0.2773, -0.6837,  ..., -0.0801, -0.1164,  0.0608],\n",
      "          [-0.2428, -0.8915,  0.4642,  ..., -0.4200,  0.2403, -0.5729],\n",
      "          [ 0.1073, -0.5361,  1.0369,  ..., -0.8047,  0.3097, -0.8743],\n",
      "          ...,\n",
      "          [-0.0244, -0.4531, -0.1106,  ...,  0.7547, -0.4684, -0.6691],\n",
      "          [ 0.1979,  0.0317,  0.3100,  ..., -0.7540, -0.3176, -0.3696],\n",
      "          [ 0.1225,  0.2364, -0.4952,  ..., -0.4072,  0.1011, -0.3659]],\n",
      "\n",
      "         [[ 0.1052, -0.3615,  0.0605,  ..., -0.6283,  0.0614, -0.2870],\n",
      "          [ 0.0198,  0.0931, -1.0559,  ...,  0.2134,  0.0439,  0.3677],\n",
      "          [-0.3456,  0.0509,  1.0400,  ...,  0.6217, -0.0444, -0.1158],\n",
      "          ...,\n",
      "          [-0.2116, -0.3449, -0.1645,  ...,  0.4323, -0.3227,  0.2265],\n",
      "          [-0.1063,  0.3661,  0.0668,  ...,  0.1501, -0.0714, -0.5190],\n",
      "          [ 0.0030, -0.2143,  0.5249,  ..., -0.2905, -0.0857,  0.5028]],\n",
      "\n",
      "         [[ 0.3008, -0.2205, -0.5408,  ..., -0.0681,  0.0248,  0.2204],\n",
      "          [ 0.3317, -0.2703,  0.4940,  ...,  0.1895,  0.1771, -0.2019],\n",
      "          [ 0.4446, -0.2782,  0.0956,  ..., -1.4731, -0.1552, -0.5107],\n",
      "          ...,\n",
      "          [ 0.1371,  0.3169,  0.3859,  ...,  0.7261, -0.3245, -0.3319],\n",
      "          [-0.3103, -0.3665, -0.0903,  ..., -0.5048,  0.0280,  0.1201],\n",
      "          [-0.3879,  0.0343, -0.3983,  ..., -0.3902,  0.2178,  0.2154]]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "AFTER SN SHAPE: torch.Size([1, 16, 28, 28])\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "ANY SPIKES: True\n",
      "AFTER AVG SHAPE: torch.Size([1, 16, 1, 1])\n",
      "tensor([[[[0.0013]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0026]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0013]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0013]]]])\n",
      "ANY SPIKES: True\n",
      "AFTER FLATTEN SHAPE: torch.Size([1, 16])\n",
      "tensor([[0.0013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0026, 0.0000,\n",
      "         0.0000, 0.0013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0013]])\n",
      "AFTER FC SHAPE: torch.Size([1, 10])\n",
      "tensor([[-0.2069,  0.1034, -0.0650, -0.1044, -0.1765, -0.1108, -0.2256,  0.0546,\n",
      "         -0.2318,  0.0381]], grad_fn=<AddmmBackward0>)\n",
      "AFTER SN2 SHAPE: torch.Size([1, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DummyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = layer.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = layer.BatchNorm2d(16)\n",
    "        self.sn1 = neuron.LIFNode(tau=2.0, surrogate_function=surrogate.Sigmoid())\n",
    "        self.avgpool = layer.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(16, 10)\n",
    "        self.sn2 = neuron.LIFNode(tau=2.0, surrogate_function=surrogate.Sigmoid())\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(f\"RAW INPUT SHAPE: {x.shape}\")\n",
    "        print(x)\n",
    "        x = self.conv1(x)\n",
    "        print(f\"AFTER CONV SHAPE: {x.shape}\")\n",
    "        print(x)\n",
    "        x = self.bn1(x)\n",
    "        print(f\"AFTER BN SHAPE: {x.shape}\")\n",
    "        print(x)\n",
    "        x = self.sn1(x)\n",
    "        print(f\"AFTER SN SHAPE: {x.shape}\")\n",
    "        print(x)\n",
    "        print(f\"ANY SPIKES: {torch.max(x) > 0}\")\n",
    "        x = self.avgpool(x)\n",
    "        print(f\"AFTER AVG SHAPE: {x.shape}\")\n",
    "        print(x)\n",
    "        print(f\"ANY SPIKES: {torch.max(x) > 0}\")\n",
    "        x  = torch.flatten(x, 1)\n",
    "        print(f\"AFTER FLATTEN SHAPE: {x.shape}\")\n",
    "        print(x)\n",
    "        x = self.fc1(x)\n",
    "        print(f\"AFTER FC SHAPE: {x.shape}\")\n",
    "        print(x)\n",
    "        x = self.sn2(x)\n",
    "        print(f\"AFTER SN2 SHAPE: {x.shape}\")\n",
    "        print(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "dummy_input = torch.randn(1, 1, 28, 28)\n",
    "dummy_model = DummyModel()\n",
    "dummy_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SewResnet18(\n",
    "    n_channels : int =1 ,\n",
    "    neuron_model: neuron.BaseNode = neuron.LIFNode,\n",
    "    surrogate_function: surrogate.SurrogateFunctionBase = surrogate.Sigmoid,\n",
    ") -> nn.Module:\n",
    "    net = sew_resnet18(\n",
    "        pretrained=False,\n",
    "        spiking_neuron=neuron_model,\n",
    "        cnf=\"IAND\",\n",
    "        surrogate_function=surrogate_function(),\n",
    "        # detach_reset=True,\n",
    "    )\n",
    "    net.conv1 = layer.Conv2d(\n",
    "        n_channels,\n",
    "        64,\n",
    "        kernel_size=(7, 7),\n",
    "        stride=(2, 2),\n",
    "        padding=(3, 3),\n",
    "        bias=False,\n",
    "    )\n",
    "    net.fc = layer.Linear(512, 10)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTRepeated(MNIST):\n",
    "    def __init__(self, *args, repeat=1, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.repeat = repeat\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super().__getitem__(index)\n",
    "        img_tensor =  torch.tensor(np.array(img), dtype=torch.float32)\n",
    "        img_tensor = img_tensor.repeat(self.repeat, 1, 1).unsqueeze(1)\n",
    "        return img_tensor, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 8\n",
    "model = SewResnet18(n_channels=1)\n",
    "functional.set_step_mode(model, step_mode='m')\n",
    "\n",
    "repeats = 10\n",
    "mnist_dataset_repeat_train = MNISTRepeated(root = \"./data\" ,train=True, repeat=repeats, download=True)\n",
    "mnist_dataset_repeat_test = MNISTRepeated(root = \"./data\" ,train=False, repeat=repeats, download=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "accuracy_metirc = Accuracy(task = \"multiclass\",num_classes=10)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    mnist_dataset_repeat_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    mnist_dataset_repeat_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-2, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_tensor_sequence(tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Creates a Matplotlib plot to visualize a sequence of grayscale images\n",
    "    from a 5D tensor of shape [T, B, C, H, W].\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): A 5D tensor containing the image sequence.\n",
    "                                 T: Time dimension (number of frames).\n",
    "                                 B: Batch size (number of samples).\n",
    "                                 C: Channel dimension (should be 1 for grayscale).\n",
    "                                 H: Height of the images.\n",
    "                                 W: Width of the images.\n",
    "    \"\"\"\n",
    "    T, B, C, H, W = tensor.shape\n",
    "\n",
    "    if C != 1:\n",
    "        raise ValueError(\"The channel dimension (C) should be 1 for grayscale images.\")\n",
    "\n",
    "    fig, axes = plt.subplots(B, T, figsize=(2 * T, 2 * B))  # Adjust figure size as needed\n",
    "\n",
    "    # Handle the case where B or T is 1 to ensure axes is iterable\n",
    "    if B == 1:\n",
    "        axes = np.array([axes])\n",
    "    if T == 1:\n",
    "        axes = axes[:, np.newaxis]\n",
    "\n",
    "    for b in range(B):\n",
    "        for t in range(T):\n",
    "            image = tensor[t, b, 0, :, :].cpu().numpy()\n",
    "            axes[b, t].imshow(image, cmap='gray')\n",
    "            axes[b, t].axis('off')  # Turn off axis labels and ticks\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_tensor_sequence(img.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display original shape\n",
    "print(f\"Original shape: {img.shape}\")\n",
    "\n",
    "# Swap first and second dimensions\n",
    "img_transposed = img.transpose(0, 1)\n",
    "\n",
    "# Display new shape\n",
    "print(f\"Transposed shape: {img_transposed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(img_transposed).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "epoch_progbar = tqdm(range(epochs), desc=\"Epoch\")\n",
    "dataloader_progbar = tqdm(train_loader, desc=\"Dataloader\")\n",
    "for epoch in epoch_progbar:\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_preds = []\n",
    "    epoch_targets = []\n",
    "    for i, (img, target) in enumerate(dataloader_progbar):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(img.transpose(0, 1)/255).mean(0)\n",
    "\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_preds.append(out)\n",
    "        epoch_targets.append(target)\n",
    "        functional.reset_net(model)\n",
    "        print(f\"Epoch {epoch}: {i}/{len(train_loader)}: loss: {loss.item():.4f}\")\n",
    "    epoch_preds = torch.cat(epoch_preds)\n",
    "    epoch_targets = torch.cat(epoch_targets)\n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_acc = accuracy_metirc(epoch_preds, epoch_targets)\n",
    "    print(f\"Epoch {epoch}: loss: {epoch_loss:.4f}, acc: {epoch_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
